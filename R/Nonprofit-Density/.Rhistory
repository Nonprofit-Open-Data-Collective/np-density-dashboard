dor.nms[which(str_detect( dor.nms, "kansas") )]
dor.nms[which(str_detect( dor.nms, "vegas") )]
dor.nms[which(str_detect( dor.nms, "angeles") )]
dor.nms[which(str_detect( dor.nms, "miami") )]
dor.nms[which(str_detect( dor.nms, "milwaukee") )]
dor.nms[which(str_detect( dor.nms, "minneapolis") )]
dor.nms[which(str_detect( dor.nms, "nashville") )]
dor.nms[which(str_detect( dor.nms, "new york") )]
dor.nms[which(str_detect( dor.nms, "new-york") )]
dor.nms[which(str_detect( dor.nms, "jersey") )]
dor.nms[which(str_detect( dor.nms, "oklahoma") )]
dor.nms[which(str_detect( dor.nms, "orlando") )]
dor.nms[which(str_detect( dor.nms, "philadelphia") )]
dor.nms[which(str_detect( dor.nms, "phoenix") )]
dor.nms[which(str_detect( dor.nms, "pittsburgh") )]
dor.nms[which(str_detect( dor.nms, "portland") )]
dor.nms[which(str_detect( dor.nms, "providence") )]
dor.nms[which(str_detect( dor.nms, "raleigh") )]
dor.nms[which(str_detect( dor.nms, "riverside") )]
dor.nms[which(str_detect( dor.nms, "sacramento") )]
dor.nms[which(str_detect( dor.nms, "antonio") )]
dor.nms[which(str_detect( dor.nms, "diego") )]
dor.nms[which(str_detect( dor.nms, "francisco") )]
dor.nms[which(str_detect( dor.nms, "jose") )]
dor.nms[which(str_detect( dor.nms, "juan") )]
dor.nms[which(str_detect( dor.nms, "seattle") )]
dor.nms[which(str_detect( dor.nms, "louis") )]
dor.nms[which(str_detect( dor.nms, "tampa") )]
dor.nms[which(str_detect( dor.nms, "virginia") )]
dor.nms[which(str_detect( dor.nms, "beach") )]
dor.nms[which(str_detect( dor.nms, "norfolk") )]
dor.nms[which(str_detect( dor.nms, "newport") )]
dor.nms[which(str_detect( dor.nms, "washington") )]
dor.nms
dor.nms[which(str_detect( dor.nms, "arlington") )]
pref <- "https://github.com/DS4PS/usa-dorling-shapefiles/blob/master/maps/metros-dorling/"
urls <- paste0( pref, msa.nms, ".geojson")
levels(as.factor( d.all$MSA))
msa.nms <- c( "atlanta-sandy-springs-marietta-ga-dorling-v2","austin-round-rock-tx-dorling-v2",
"baltimore-towson-md-dorling-v2", "boston-quincy-ma-dorling-v2",
"charlotte-gastonia-concord-nc-sc-dorling-v2","chicago-naperville-joliet-il-dorling-v2",
"cincinnati-middletown-oh-ky-in-dorling-v2","cleveland-tn-dorling-v2",
"columbus-oh-dorling-v2","dallas-plano-irving-tx-dorling-v2","denver-aurora-co-dorling-v2",
"detroit-livonia-dearborn-mi-dorling-v2","houston-baytown-sugar-land-tx-dorling-v2",
"indianapolis-in-dorling-v2", "jacksonville-fl-dorling-v2", "kansas-city-mo-ks-dorling-v2",
"las-vegas-paradise-nv-dorling-v2", "los-angeles-long-beach-santa-ana-ca-dorling-v2",
"miami-miami-beach-kendall-fl-dorling-v2", "milwaukee-waukesha-west-allis-wi-dorling-v1",
"minneapolis-st.-paul-bloomington-mn-wi-dorling-v2", "nashville-davidson--murfreesboro-tn-dorling-v2",
"new-york-wayne-white-plains-ny-nj-dorling-v2", "oklahoma-city-ok-dorling-v2",
"orlando-fl-dorling-v2", "philadelphia-pa-dorling-v2", "phoenix-mesa-scottsdale-az-dorling-v2",
"pittsburgh-pa-dorling-v2", "portland-vancouver-beaverton-or-wa-dorling-v2",
"providence-new-bedford-fall-river-ri-m-dorling-v2", "raleigh-cary-nc-dorling-v2",
"riverside-san-bernardino-ontario-ca-dorling-v2", "sacramento--arden-arcade--roseville-ca-dorling-v2",
"san-antonio-tx-dorling-v2", "san-diego-carlsbad-san-marcos-ca-dorling-v2",
"san-francisco-san-mateo-redwood-cityca-dorling-v2", "san-jose-sunnyvale-santa-clara-ca-dorling-v2",
"san-juan-caguas-guaynabo-pr-dorling-v1", "seattle-bellevue-everett-wa-dorling-v1",
"st.-louis-mo-il-dorling-v2", "tampa-st.-petersburg-clearwater-fl-dorling-v2",
)
pref <- "https://github.com/DS4PS/usa-dorling-shapefiles/blob/master/maps/metros-dorling/"
dor.nms[which(str_detect( dor.nms, "arlington") )]
urls <- paste0( pref, msa.nms, ".geojson")
msa.nms <- c( "atlanta-sandy-springs-marietta-ga-dorling-v2","austin-round-rock-tx-dorling-v2",
"baltimore-towson-md-dorling-v2", "boston-quincy-ma-dorling-v2",
"charlotte-gastonia-concord-nc-sc-dorling-v2","chicago-naperville-joliet-il-dorling-v2",
"cincinnati-middletown-oh-ky-in-dorling-v2","cleveland-tn-dorling-v2",
"columbus-oh-dorling-v2","dallas-plano-irving-tx-dorling-v2","denver-aurora-co-dorling-v2",
"detroit-livonia-dearborn-mi-dorling-v2","houston-baytown-sugar-land-tx-dorling-v2",
"indianapolis-in-dorling-v2", "jacksonville-fl-dorling-v2", "kansas-city-mo-ks-dorling-v2",
"las-vegas-paradise-nv-dorling-v2", "los-angeles-long-beach-santa-ana-ca-dorling-v2",
"miami-miami-beach-kendall-fl-dorling-v2", "milwaukee-waukesha-west-allis-wi-dorling-v1",
"minneapolis-st.-paul-bloomington-mn-wi-dorling-v2", "nashville-davidson--murfreesboro-tn-dorling-v2",
"new-york-wayne-white-plains-ny-nj-dorling-v2", "oklahoma-city-ok-dorling-v2",
"orlando-fl-dorling-v2", "philadelphia-pa-dorling-v2", "phoenix-mesa-scottsdale-az-dorling-v2",
"pittsburgh-pa-dorling-v2", "portland-vancouver-beaverton-or-wa-dorling-v2",
"providence-new-bedford-fall-river-ri-m-dorling-v2", "raleigh-cary-nc-dorling-v2",
"riverside-san-bernardino-ontario-ca-dorling-v2", "sacramento--arden-arcade--roseville-ca-dorling-v2",
"san-antonio-tx-dorling-v2", "san-diego-carlsbad-san-marcos-ca-dorling-v2",
"san-francisco-san-mateo-redwood-cityca-dorling-v2", "san-jose-sunnyvale-santa-clara-ca-dorling-v2",
"san-juan-caguas-guaynabo-pr-dorling-v1", "seattle-bellevue-everett-wa-dorling-v1",
"st.-louis-mo-il-dorling-v2", "tampa-st.-petersburg-clearwater-fl-dorling-v2"
)
urls <- paste0( pref, msa.nms, ".geojson")
urls
st.in <- list()
for( i in 1: length( msa.nms) ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
st.in[[i]] <- st_transform( in.st, crs = 3395 ) # project onto compatible crs
}
st.in <- list()
for( i in 1: length( msa.nms) ){
start.time <- Sys.time()
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
st.in[[i]] <- st_transform( in.st, crs = 3395 ) # project onto compatible crs
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
pref <- "https://raw.githubusercontent.com/DS4PS/usa-dorling-shapefiles/master/maps/metros-dorling/"
urls <- paste0( pref, msa.nms, ".geojson")
st.in <- list()
for( i in 1: length( msa.nms) ){
start.time <- Sys.time()
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
st.in[[i]] <- st_transform( in.st, crs = 3395 ) # project onto compatible crs
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
setwd( lf )
lf
setwd( paste0( lf, "Dorling-GeoJson-Files" ) )
paste0( lf, "Dorling-GeoJson-Files" )
setwd( paste0( lf, "/Dorling-GeoJson-Files" ) )
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- list()
dat.msa.nms <- levels(as.factor( d.all$MSA ) )
dat.msa.nms
dat.msa.nms[i]
dat.msa.nms <- levels(as.factor( d.all$MSA ) )
url.msa.nms <- c( "atlanta-sandy-springs-marietta-ga-dorling-v2","austin-round-rock-tx-dorling-v2",
"baltimore-towson-md-dorling-v2", "boston-quincy-ma-dorling-v2",
"charlotte-gastonia-concord-nc-sc-dorling-v2","chicago-naperville-joliet-il-dorling-v2",
"cincinnati-middletown-oh-ky-in-dorling-v2","cleveland-tn-dorling-v2",
"columbus-oh-dorling-v2","dallas-plano-irving-tx-dorling-v2","denver-aurora-co-dorling-v2",
"detroit-livonia-dearborn-mi-dorling-v2","houston-baytown-sugar-land-tx-dorling-v2",
"indianapolis-in-dorling-v2", "jacksonville-fl-dorling-v2", "kansas-city-mo-ks-dorling-v2",
"las-vegas-paradise-nv-dorling-v2", "los-angeles-long-beach-santa-ana-ca-dorling-v2",
"miami-miami-beach-kendall-fl-dorling-v2", "milwaukee-waukesha-west-allis-wi-dorling-v1",
"minneapolis-st.-paul-bloomington-mn-wi-dorling-v2", "nashville-davidson--murfreesboro-tn-dorling-v2",
"new-york-wayne-white-plains-ny-nj-dorling-v2", "oklahoma-city-ok-dorling-v2",
"orlando-fl-dorling-v2", "philadelphia-pa-dorling-v2", "phoenix-mesa-scottsdale-az-dorling-v2",
"pittsburgh-pa-dorling-v2", "portland-vancouver-beaverton-or-wa-dorling-v2",
"providence-new-bedford-fall-river-ri-m-dorling-v2", "raleigh-cary-nc-dorling-v2",
"riverside-san-bernardino-ontario-ca-dorling-v2", "sacramento--arden-arcade--roseville-ca-dorling-v2",
"san-antonio-tx-dorling-v2", "san-diego-carlsbad-san-marcos-ca-dorling-v2",
"san-francisco-san-mateo-redwood-cityca-dorling-v2", "san-jose-sunnyvale-santa-clara-ca-dorling-v2",
"san-juan-caguas-guaynabo-pr-dorling-v1", "seattle-bellevue-everett-wa-dorling-v1",
"st.-louis-mo-il-dorling-v2", "tampa-st.-petersburg-clearwater-fl-dorling-v2"
)
pref <- "https://raw.githubusercontent.com/DS4PS/usa-dorling-shapefiles/master/maps/metros-dorling/"
dor.nms[which(str_detect( dor.nms, "arlington") )]
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- data.frame()
for( i in 1: length( msa.nms) ){
start.time <- Sys.time()
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- bind_rows( st.in, in.st )              # bind rows into data.frame
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
d.all[, d.all$pop]
d.all[, "pop"]
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- data.frame()
for( i in 1: length( msa.nms) ){
start.time <- Sys.time()
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- bind_rows( st.in, in.st[, "MSA" ] )   # bind rows into data.frame and keep only identifier column
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
i=1
start.time <- Sys.time()
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- bind_rows( st.in, in.st[, "MSA" ] )   # bind rows into data.frame and keep only identifier column
st.in <- rbind( st.in, in.st[, "MSA" ] )   # bind rows into data.frame and keep only identifier column
st.in
st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ] ) ) )
st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- data.frame()
st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- data.frame()
for( i in 1: length( msa.nms) ){
start.time <- Sys.time()
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
setwd( paste0( lf, "/Dorling-GeoJson-Files" ) )
dir()
paste0( msa.nms[i], ".geojson" )
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- data.frame()
setwd( paste0( lf, "/Dorling-GeoJson-Files" ) )   # path for Virginia Beach and Washington Dorling Files
for( i in 1: length( msa.nms) ){
start.time <- Sys.time()
if ( i in 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
else if ( i in 42:43 ){
st_read( paste0( msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
for( i in 1: length( msa.nms) ){
start.time <- Sys.time()
# URLs
if ( i in 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
# physical files in path
if ( i in 42:43 ){
in.st <- st_read( paste0( msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
i=1
# URLs
if ( i in 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
1:length( msa.nms)
for( i in 1:length( msa.nms) ){
start.time <- Sys.time()
# URLs
if ( i in 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
# physical files in path
if ( i in 42:43 ){
in.st <- st_read( paste0( msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
length( msa.nms)
for( i in 1:length( url.msa.nms) ){
start.time <- Sys.time()
# URLs
if ( i in 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
# physical files in path
if ( i in 42:43 ){
in.st <- st_read( paste0( msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
for( i in 1:length( url.msa.nms) ){
start.time <- Sys.time()
# URLs
if ( i %in% 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
# physical files in path
if ( i %in% 42:43 ){
in.st <- st_read( paste0( msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
url.msa.nms <- c( "atlanta-sandy-springs-marietta-ga-dorling-v2","austin-round-rock-tx-dorling-v2",
"baltimore-towson-md-dorling-v2", "boston-quincy-ma-dorling-v2",
"charlotte-gastonia-concord-nc-sc-dorling-v2","chicago-naperville-joliet-il-dorling-v2",
"cincinnati-middletown-oh-ky-in-dorling-v2","cleveland-tn-dorling-v2",
"columbus-oh-dorling-v2","dallas-plano-irving-tx-dorling-v2","denver-aurora-co-dorling-v2",
"detroit-livonia-dearborn-mi-dorling-v2","houston-baytown-sugar-land-tx-dorling-v2",
"indianapolis-in-dorling-v2", "jacksonville-fl-dorling-v2", "kansas-city-mo-ks-dorling-v2",
"las-vegas-paradise-nv-dorling-v2", "los-angeles-long-beach-santa-ana-ca-dorling-v2",
"miami-miami-beach-kendall-fl-dorling-v2", "milwaukee-waukesha-west-allis-wi-dorling-v1",
"minneapolis-st.-paul-bloomington-mn-wi-dorling-v2", "nashville-davidson--murfreesboro-tn-dorling-v2",
"new-york-wayne-white-plains-ny-nj-dorling-v2", "oklahoma-city-ok-dorling-v2",
"orlando-fl-dorling-v2", "philadelphia-pa-dorling-v2", "phoenix-mesa-scottsdale-az-dorling-v2",
"pittsburgh-pa-dorling-v2", "portland-vancouver-beaverton-or-wa-dorling-v2",
"providence-new-bedford-fall-river-ri-m-dorling-v2", "raleigh-cary-nc-dorling-v2",
"riverside-san-bernardino-ontario-ca-dorling-v2", "sacramento--arden-arcade--roseville-ca-dorling-v2",
"san-antonio-tx-dorling-v2", "san-diego-carlsbad-san-marcos-ca-dorling-v2",
"san-francisco-san-mateo-redwood-cityca-dorling-v2", "san-jose-sunnyvale-santa-clara-ca-dorling-v2",
"san-juan-caguas-guaynabo-pr-dorling-v1", "seattle-bellevue-everett-wa-dorling-v1",
"st.-louis-mo-il-dorling-v2", "tampa-st.-petersburg-clearwater-fl-dorling-v2",
"virginia-beach-norfolk-newport-news-va-dorling-v2", "washington-arlington-alexandria-dc-va-dorling-v2")
pref <- "https://raw.githubusercontent.com/DS4PS/usa-dorling-shapefiles/master/maps/metros-dorling/"
dor.nms[which(str_detect( dor.nms, "arlington") )]
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- data.frame()
setwd( paste0( lf, "/Dorling-GeoJson-Files" ) )   # path for Virginia Beach and Washington Dorling Files
for( i in 1:length( url.msa.nms) ){
start.time <- Sys.time()
# URLs
if ( i %in% 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
# physical files in path
if ( i %in% 42:43 ){
in.st <- st_read( paste0( msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( msa.nms ), " complete" ) )
}
dat.msa.nms <- levels(as.factor( d.all$MSA ) )
url.msa.nms <- c( "atlanta-sandy-springs-marietta-ga-dorling-v2","austin-round-rock-tx-dorling-v2",
"baltimore-towson-md-dorling-v2", "boston-quincy-ma-dorling-v2",
"charlotte-gastonia-concord-nc-sc-dorling-v2","chicago-naperville-joliet-il-dorling-v2",
"cincinnati-middletown-oh-ky-in-dorling-v2","cleveland-tn-dorling-v2",
"columbus-oh-dorling-v2","dallas-plano-irving-tx-dorling-v2","denver-aurora-co-dorling-v2",
"detroit-livonia-dearborn-mi-dorling-v2","houston-baytown-sugar-land-tx-dorling-v2",
"indianapolis-in-dorling-v2", "jacksonville-fl-dorling-v2", "kansas-city-mo-ks-dorling-v2",
"las-vegas-paradise-nv-dorling-v2", "los-angeles-long-beach-santa-ana-ca-dorling-v2",
"miami-miami-beach-kendall-fl-dorling-v2", "milwaukee-waukesha-west-allis-wi-dorling-v1",
"minneapolis-st.-paul-bloomington-mn-wi-dorling-v2", "nashville-davidson--murfreesboro-tn-dorling-v2",
"new-york-wayne-white-plains-ny-nj-dorling-v2", "oklahoma-city-ok-dorling-v2",
"orlando-fl-dorling-v2", "philadelphia-pa-dorling-v2", "phoenix-mesa-scottsdale-az-dorling-v2",
"pittsburgh-pa-dorling-v2", "portland-vancouver-beaverton-or-wa-dorling-v2",
"providence-new-bedford-fall-river-ri-m-dorling-v2", "raleigh-cary-nc-dorling-v2",
"riverside-san-bernardino-ontario-ca-dorling-v2", "sacramento--arden-arcade--roseville-ca-dorling-v2",
"san-antonio-tx-dorling-v2", "san-diego-carlsbad-san-marcos-ca-dorling-v2",
"san-francisco-san-mateo-redwood-cityca-dorling-v2", "san-jose-sunnyvale-santa-clara-ca-dorling-v2",
"san-juan-caguas-guaynabo-pr-dorling-v1", "seattle-bellevue-everett-wa-dorling-v1",
"st.-louis-mo-il-dorling-v2", "tampa-st.-petersburg-clearwater-fl-dorling-v2",
"virginia-beach-norfolk-newport-news-va-dorling-v2", "washington-arlington-alexandria-dc-va-dorling-v2")
pref <- "https://raw.githubusercontent.com/DS4PS/usa-dorling-shapefiles/master/maps/metros-dorling/"
dor.nms[which(str_detect( dor.nms, "arlington") )]
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- data.frame()
setwd( paste0( lf, "/Dorling-GeoJson-Files" ) )   # path for Virginia Beach and Washington Dorling Files
for( i in 1:length( url.msa.nms) ){
start.time <- Sys.time()
# URLs
if ( i %in% 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
# physical files in path
if ( i %in% 42:43 ){
in.st <- st_read( paste0( msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( url.msa.nms ), " complete" ) )
}
url.msa.nms[i]
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- data.frame()
setwd( paste0( lf, "/Dorling-GeoJson-Files" ) )   # path for Virginia Beach and Washington Dorling Files
for( i in 1:length( url.msa.nms) ){
start.time <- Sys.time()
# URLs
if ( i %in% 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
# physical files in path
if ( i %in% 42:43 ){
in.st <- st_read( paste0( url.msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( url.msa.nms ), " complete" ) )
}
setwd( lf )
setwd("../np-density-dashboard/Data-Rodeo")
# dir.create( "Dashboard-MSA-Data" )
# dir()
setwd("Dashboard-MSA-Data")
d.4 <- readRDS( "USA-MSAs.rds" )
dat.msa.nms <- levels(as.factor( d.4$MSA ) )
url.msa.nms <- c( "atlanta-sandy-springs-marietta-ga-dorling-v2","austin-round-rock-tx-dorling-v2",
"baltimore-towson-md-dorling-v2", "boston-quincy-ma-dorling-v2",
"charlotte-gastonia-concord-nc-sc-dorling-v2","chicago-naperville-joliet-il-dorling-v2",
"cincinnati-middletown-oh-ky-in-dorling-v2","cleveland-tn-dorling-v2",
"columbus-oh-dorling-v2","dallas-plano-irving-tx-dorling-v2","denver-aurora-co-dorling-v2",
"detroit-livonia-dearborn-mi-dorling-v2","houston-baytown-sugar-land-tx-dorling-v2",
"indianapolis-in-dorling-v2", "jacksonville-fl-dorling-v2", "kansas-city-mo-ks-dorling-v2",
"las-vegas-paradise-nv-dorling-v2", "los-angeles-long-beach-santa-ana-ca-dorling-v2",
"miami-miami-beach-kendall-fl-dorling-v2", "milwaukee-waukesha-west-allis-wi-dorling-v1",
"minneapolis-st.-paul-bloomington-mn-wi-dorling-v2", "nashville-davidson--murfreesboro-tn-dorling-v2",
"new-york-wayne-white-plains-ny-nj-dorling-v2", "oklahoma-city-ok-dorling-v2",
"orlando-fl-dorling-v2", "philadelphia-pa-dorling-v2", "phoenix-mesa-scottsdale-az-dorling-v2",
"pittsburgh-pa-dorling-v2", "portland-vancouver-beaverton-or-wa-dorling-v2",
"providence-new-bedford-fall-river-ri-m-dorling-v2", "raleigh-cary-nc-dorling-v2",
"riverside-san-bernardino-ontario-ca-dorling-v2", "sacramento--arden-arcade--roseville-ca-dorling-v2",
"san-antonio-tx-dorling-v2", "san-diego-carlsbad-san-marcos-ca-dorling-v2",
"san-francisco-san-mateo-redwood-cityca-dorling-v2", "san-jose-sunnyvale-santa-clara-ca-dorling-v2",
"san-juan-caguas-guaynabo-pr-dorling-v1", "seattle-bellevue-everett-wa-dorling-v1",
"st.-louis-mo-il-dorling-v2", "tampa-st.-petersburg-clearwater-fl-dorling-v2",
"virginia-beach-norfolk-newport-news-va-dorling-v2", "washington-arlington-alexandria-dc-va-dorling-v2")
pref <- "https://raw.githubusercontent.com/DS4PS/usa-dorling-shapefiles/master/maps/metros-dorling/"
urls <- paste0( pref, url.msa.nms, ".geojson")
st.in <- data.frame()
setwd( paste0( lf, "/Dorling-GeoJson-Files" ) )   # path for Virginia Beach and Washington Dorling Files
st.in
st.in <- data.frame()                             # initialize data.frame
for( i in 1:length( url.msa.nms) ){
start.time <- Sys.time()
# URLs
if ( i %in% 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
# physical files in path
if ( i %in% 42:43 ){
in.st <- st_read( paste0( url.msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( url.msa.nms ), " complete" ) )
}
st.in
d.dorling <- left_join( st_drop_geometry( d.4 ), data.frame( st.in ), by = "GEOID" )
urls <- paste0( pref, url.msa.nms, ".geojson")
setwd( paste0( lf, "/Dorling-GeoJson-Files" ) )   # path for Virginia Beach and Washington Dorling Files
st.in <- data.frame()                             # initialize data.frame
for( i in 1:length( url.msa.nms) ){
start.time <- Sys.time()
# URLs
if ( i %in% 1:41 ){
in.st <- st_read( urls[i] )                     # read in geoJSON and convert to sf
}
# physical files in path
if ( i %in% 42:43 ){
in.st <- st_read( paste0( url.msa.nms[i], ".geojson" ) )
}
in.st <- st_transform( in.st, crs = 3395 )      # project onto compatible crs
in.st$MSA <- dat.msa.nms[i]                     # add MSA name identifier for merge
st.in <- st_as_sf( rbind( st.in, in.st[, c( "GEOID", "MSA" ) ] ) )  # bind rows into data.frame and keep only identifier columns
st.in$GEOID <- as.character( st.in$GEOID )
end.time <- Sys.time()
print( end.time - start.time)
print( paste0( "Iteration ", i, "/", length( url.msa.nms ), " complete" ) )
}
d.dorling <- left_join( st_drop_geometry( d.4 ), data.frame( st.in ), by = "GEOID" )
d.dorling <- st_as_sf( left_join( st_drop_geometry( d.4 ), data.frame( st.in ), by = "GEOID" ) )
setwd("../np-density-dashboard/Data-Rodeo/Dashboard-MSA-Data/Dorling-Shapefiles")
setwd( lf )
setwd("../np-density-dashboard/Data-Rodeo/Dashboard-MSA-Data/Dorling-Shapefiles")
d.dorling,msa <- st_as_sf( left_join( st_drop_geometry( d.4 ), data.frame( st.in ), by = "GEOID" ) )
d.dorling.msa <- st_as_sf( left_join( st_drop_geometry( d.4 ), data.frame( st.in ), by = "GEOID" ) )
setwd( lf )
setwd("../np-density-dashboard/Data-Rodeo/Dashboard-MSA-Data/Dorling-Shapefiles")
saveRDS( d.dorling.msa , "USA-MSAs-Dorling.rds" )
d.dorling.msa <- st_as_sf( left_join( st_drop_geometry( d.4 ), data.frame( st.in ), by = c( "GEOID", "MSA" ) ) )
setwd( lf )
setwd("../np-density-dashboard/Data-Rodeo/Dashboard-MSA-Data/Dorling-Shapefiles")
saveRDS( d.dorling.msa , "USA-MSAs-Dorling.rds" )
runApp('/Volumes/My Passport for Mac/Urban Institute/Summer Projects/Geospatial Dashboard/np-density-dashboard/R/Nonprofit-Density')
setwd( paste0( main, "np-density-dashboard/Data-Rodeo/Dashboard-MSA-Data/Dorling-Shapefiles" ) )
# Import counties landing page map
main <- "/Volumes/My Passport for Mac/Urban Institute/Summer Projects/Geospatial Dashboard/"
setwd( paste0( main, "np-density-dashboard/Data-Rodeo/Dashboard-MSA-Data/Dorling-Shapefiles" ) )
msas.dorling <- readRDS( "USA-MSAs-Dorling.rds" )
lp.plot.chloro <- function( df, input ){
# there are issues binning variables with high quantitites of zero values. Thus,
# we will separate the zero and non-zero values of the metrics into separate datasets, bin them separately
# and then row bind them back together for the final plot:
df.zeros <- df[df[[ input ]] == 0, ] # metric = 0
df.zeros[[ paste0( input ) ]] <- 0           # assign value of zero for the ordinal variable
df.nonzeros <- df[df[[ input ]] != 0,] # metric != 0
df.nonzeros[[ paste0( input  ) ]] <- factor( quant.cut( var = input, x = 6 , df = df.nonzeros ) ) # bin into 6
# ordinal categories
df.out <- rbind( df.zeros, df.nonzeros)  # bind
df.out[[ paste0( input  ) ]] <- factor( df.out[[ paste0( input  ) ]] ) # set to factor
ggplot( ) + geom_sf( df.out,             # plot
mapping = aes_string( fill = paste0( input ) ),
color = NA, size = 0.5 ) +
scale_fill_brewer( "Density Scale", palette = 1 ) +
theme_minimal( ) +
theme( text = element_text( family = "Avenir" ) )
}
lp.plot.chloro( df = msas.dorling %>% filter( year == "cum" & MSA == "Boston-Cambridge-Newton" ), input = "dens"  )
lp.plot.chloro( df = msas.dorling %>% filter( year == "cum" & MSA == "Washington-Arlington-Alexandria ), input = "dens"  )
lp.plot.chloro( df = msas.dorling %>% filter( year == "cum" & MSA == "Washington-Arlington-Alexandria" ), input = "dens"  )
runApp('/Volumes/My Passport for Mac/Urban Institute/Summer Projects/Geospatial Dashboard/np-density-dashboard/R/Nonprofit-Density')
runApp('/Volumes/My Passport for Mac/Urban Institute/Summer Projects/Geospatial Dashboard/np-density-dashboard/R/Nonprofit-Density')
runApp('/Volumes/My Passport for Mac/Urban Institute/Summer Projects/Geospatial Dashboard/np-density-dashboard/R/Nonprofit-Density')
runApp('/Volumes/My Passport for Mac/Urban Institute/Summer Projects/Geospatial Dashboard/np-density-dashboard/R/Nonprofit-Density')
